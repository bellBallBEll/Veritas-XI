{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe98008-cdc7-40b6-a0ef-997cb9248f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines player positions\n",
    "\n",
    "POSITION_TABLE_MAP = {\n",
    "    'FW': 'scout_full_FW',\n",
    "    'AM': 'scout_full_AM',\n",
    "    'MF': 'scout_full_MF',\n",
    "    'FB': 'scout_full_FB',\n",
    "    'CB': 'scout_full_CB',\n",
    "    'GK': 'scout_full_GK'\n",
    "}\n",
    "\n",
    "def get_primary_position(soup):\n",
    "    meta = soup.find('div', id='meta')\n",
    "    if not meta:\n",
    "        return None\n",
    "\n",
    "    pos_strong = meta.find('strong', string='Position:')\n",
    "    if not pos_strong:\n",
    "        return None\n",
    "\n",
    "    position_text = pos_strong.next_sibling.strip()\n",
    "    return position_text.split(',')[0].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95886a0a-a367-4280-a152-c631ef9d1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the player positions for scraping\n",
    "def get_primary_position(soup):\n",
    "    meta = soup.find('div', id='meta')\n",
    "    if not meta:\n",
    "        return None\n",
    "\n",
    "    pos_strong = meta.find('strong', string='Position:')\n",
    "    if not pos_strong:\n",
    "        return None\n",
    "\n",
    "    position_text = pos_strong.next_sibling.strip()\n",
    "    primary_position = position_text.split(',')[0].strip()\n",
    "\n",
    "    return primary_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5259ebd4-ef21-4900-9abe-d5667c73f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS AND SETUPS\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Path to MSEdgeDriver executable\n",
    "edge_driver_path = \"msedgedriver.exe\"\n",
    "\n",
    "\n",
    "def scrape_player_data(player_url):\n",
    "# 1. INITIALIZE DRIVERS\n",
    "    service = Service(executable_path=edge_driver_path)\n",
    "    options = webdriver.EdgeOptions()\n",
    "    # options.add_argument(\"--headless\") # Uncomment to not have browser window pop-up\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    driver = webdriver.Edge(service=service, options=options)\n",
    "    \n",
    "    print(f\"Opening URL with Selenium (Edge): {player_url}\")\n",
    "    driver.get(player_url)\n",
    "    # Parse page HTML\n",
    "    html_content_selenium = driver.page_source\n",
    "    soup_selenium = BeautifulSoup(html_content_selenium, 'html.parser')\n",
    "    # Detect player position\n",
    "    player_position = get_primary_position(soup_selenium)\n",
    "    print(f\"Detected position: {player_position}\")\n",
    "\n",
    "\n",
    "# 2. WAIT FOR CORRECT SCOUTING TABLE TO LOAD\n",
    "table_id = POSITION_TABLE_MAP.get(player_position)\n",
    "\n",
    "if not table_id:\n",
    "    print(f\"No complete scouting table for position {player_position}\")\n",
    "    driver.quit()\n",
    "    return None\n",
    "# Waiting for table\n",
    "try:\n",
    "    WebDriverWait(driver, 30).until(\n",
    "        EC.presence_of_element_located((By.ID, table_id))\n",
    "    )\n",
    "    print(f\"Table element '{table_id}' found.\")\n",
    "    time.sleep(2)  # Ethical scraping delay\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not find table {table_id} for {player_url}. Error: {e}\")\n",
    "    driver.quit()\n",
    "    return None\n",
    "\n",
    "# 3. SCRAPE DATA\n",
    "html_content_selenium = driver.page_source\n",
    "soup_selenium = BeautifulSoup(html_content_selenium, 'html.parser')\n",
    "# Extracting table\n",
    "target_table_selenium = soup_selenium.find('table', {'id': table_id})\n",
    "\n",
    "# 4. PARSE TABLE INTO DATAFRAME\n",
    "if target_table_selenium:\n",
    "    df_list = pd.read_html(str(target_table_selenium))\n",
    "    if df_list:\n",
    "        player_df = df_list[0]\n",
    "        print(f\"Successfully scraped DataFrame of shape: {player_df.shape}\")\n",
    "\n",
    "        # 5. QUIT DRIVER SAFELY\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return player_df\n",
    "\n",
    "print(\"ERROR: Failed to parse table into a DataFrame.\")\n",
    "driver.quit()\n",
    "return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b914ec6-e450-4fae-9c36-fb8d8613e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTI-PLAYER LOOP AND DATA AGGREGATION\n",
    "\n",
    "# 1. LIST OF PLAYER URLs\n",
    "player_urls = [\n",
    "    \"https://fbref.com/en/players/1f44ac21/scout/12524/Erling-Haaland-Scouting-Report\",\n",
    "    \"https://fbref.com/en/players/b282337d/scout/12524/Cole-Palmer-Scouting-Report\",\n",
    "    \"https://fbref.com/en/players/e342ad68/scout/12524/Mohamed-Salah-Scouting-Report\",\n",
    "    # Add more player URLs here later\n",
    "]\n",
    "\n",
    "# 2. EXECUTE THE LOOP\n",
    "all_player_data = []\n",
    "\n",
    "for url in player_urls:\n",
    "    df = scrape_player_data(url)\n",
    "    \n",
    "    # Adds DataFrame if scraping was successful\n",
    "    if df is not None:\n",
    "        all_player_data.append(df)\n",
    "        \n",
    "        # Adds long pauses between players to be polite to the website\n",
    "        # For ethical multi-player scraping\n",
    "        time.sleep(10)\n",
    "\n",
    "# 3. COMBINE AND SAVE DATA\n",
    "if all_player_data:\n",
    "    # Concatenate all individual player DataFrames into one DataFrame\n",
    "    final_scouting_df = pd.concat(all_player_data, ignore_index=True)\n",
    "    \n",
    "    # Save the combined DataFrame\n",
    "    output_filename = \"all_player_scouting_report.csv\"\n",
    "    final_scouting_df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(\"\\n----------------------------------------------------\")\n",
    "    print(\"Multi-Player Scraping Complete!\")\n",
    "    print(f\"Total rows scraped: {final_scouting_df.shape[0]}\")\n",
    "    print(f\"Combined data saved to {output_filename}\")\n",
    "else:\n",
    "    print(\"No player data was successfully scraped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc832f3-94a9-4ca6-a18f-e5ce325171d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_scout_df = player_scout_df.copy() \n",
    "player_scout_df.columns = ['_'.join(col).strip() for col in player_scout_df.columns.values]\n",
    "\n",
    "# Fill all non number values with 0\n",
    "player_scout_df.fillna(0, inplace=True)\n",
    "\n",
    "columns_to_convert = ['Standard_Gls', 'Standard_Ast', 'Performance_SCA', 'Performance_GCA'] \n",
    "\n",
    "for col in columns_to_convert:\n",
    "\n",
    "    player_scout_df[col] = pd.to_numeric(player_scout_df[col], errors='coerce')\n",
    "\n",
    "# Fill new non number values with 0\n",
    "player_scout_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beda44f1-805e-4deb-9345-75fb518e819d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Standard Stats Standard Stats.1 Standard Stats.2\n",
      "0             Statistic           Per 90       Percentile\n",
      "1     Non-Penalty Goals             0.63             92.0\n",
      "2  npxG: Non-Penalty xG             0.62             94.0\n",
      "3           Shots Total             3.42             88.0\n",
      "4               Assists             0.10             34.0\n"
     ]
    }
   ],
   "source": [
    "# To import the data from the CSV file\n",
    "import pandas as pd\n",
    "df = pd.read_csv('erling_haaland_scouting_report.csv')\n",
    "\n",
    "# To display the first 5 rows \n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee12bbf2-a707-40e6-b493-99e890468d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
